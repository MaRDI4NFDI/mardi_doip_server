{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Strict DOIP v2.0 implementation for FAIR Digital Objects (FDOs), backed by lakeFS storage and an FDO fa\u00e7ade. This site covers how to run the server, call it from Python or the CLI, configure TLS, and build the Docker image. Why DOIP and FDO? FAIR Digital Objects (FDOs) provide persistent identifiers plus structured metadata and component links, improving interoperability and long-term access. Digital Object Interface Protocol (DOIP) standardizes how to fetch and operate on those objects over the network using binary envelopes and operation codes. This project supplies both sides\u2014server and client\u2014so MaRDI services can publish and consume FDO content (bitstreams, derived components, workflow results) consistently. Capabilities at a glance Binary DOIP listener on TCP ( 3567 by default) with automatic TLS when certs/server.crt and certs/server.key exist. Compatibility JSON-segment listener on port + 1 ( 3568 by default) for doipy-style clients. Operations: hello , retrieve , invoke , plus a list_ops helper. lakeFS-backed component retrieval and workflow-driven derived components. Quick start 1) Start the server (plaintext example): PYTHONPATH=. python -m doip_server.main --port 3567 2) Retrieve an object with the CLI: PYTHONPATH=. python -m client_cli.main \\ --host 127.0.0.1 --port 3567 --no-tls \\ --action retrieve --object-id Q6190920 --output . The CLI issues hello then retrieve , prints returned metadata, and saves the first component using the server-provided filename when available. See Configuration to point the server at your lakeFS and FDO endpoints, and Docker for containerized runs.","title":"Home"},{"location":"#why-doip-and-fdo","text":"FAIR Digital Objects (FDOs) provide persistent identifiers plus structured metadata and component links, improving interoperability and long-term access. Digital Object Interface Protocol (DOIP) standardizes how to fetch and operate on those objects over the network using binary envelopes and operation codes. This project supplies both sides\u2014server and client\u2014so MaRDI services can publish and consume FDO content (bitstreams, derived components, workflow results) consistently.","title":"Why DOIP and FDO?"},{"location":"#capabilities-at-a-glance","text":"Binary DOIP listener on TCP ( 3567 by default) with automatic TLS when certs/server.crt and certs/server.key exist. Compatibility JSON-segment listener on port + 1 ( 3568 by default) for doipy-style clients. Operations: hello , retrieve , invoke , plus a list_ops helper. lakeFS-backed component retrieval and workflow-driven derived components.","title":"Capabilities at a glance"},{"location":"#quick-start","text":"1) Start the server (plaintext example): PYTHONPATH=. python -m doip_server.main --port 3567 2) Retrieve an object with the CLI: PYTHONPATH=. python -m client_cli.main \\ --host 127.0.0.1 --port 3567 --no-tls \\ --action retrieve --object-id Q6190920 --output . The CLI issues hello then retrieve , prints returned metadata, and saves the first component using the server-provided filename when available. See Configuration to point the server at your lakeFS and FDO endpoints, and Docker for containerized runs.","title":"Quick start"},{"location":"client/","text":"doip_client implements a strict DOIP v2.0 client that mirrors the server framing (binary envelope, metadata/component/workflow blocks) and supports TLS. Core operations hello() : Health check and capability discovery. list_ops() : Fetch the availableOperations map. retrieve(object_id, component=None) : Return metadata blocks or a specific component. invoke(object_id, workflow, params=None) : Trigger a workflow; receives workflow metadata and derived components. Usage from doip_client import StrictDOIPClient client = StrictDOIPClient(host=\"127.0.0.1\", port=3567, use_tls=False) hello = client.hello() ops = client.list_ops() metadata = client.retrieve(\"Q123\").metadata_blocks pdf = client.retrieve(\"Q123\", component=\"doip:bitstream/Q123/main-pdf\") # Invoke a workflow with parameters result = client.invoke(\"Q123\", workflow=\"equation_extraction\", params={\"pages\": [1, 2, 3]}) TLS & verification Pass use_tls=True to wrap the socket. If you use self-signed certs during development, combine use_tls=True with verify=False to skip hostname verification. Timeouts & clean up The client uses blocking sockets; wrap calls in your own timeout logic if needed. Always close the client when finished: client.close() Component handling For metadata-only requests, send no component and inspect response.metadata_blocks . For binaries, pass the component ID; the client returns ComponentBlock objects containing component_id , media_type , and content bytes. Compatibility listener support The Python client speaks strict DOIP. To talk to the compatibility JSON-segment listener ( port + 1 ), use the Client CLI which wraps the same client but performs JSON bridging for you.","title":"Client"},{"location":"client/#core-operations","text":"hello() : Health check and capability discovery. list_ops() : Fetch the availableOperations map. retrieve(object_id, component=None) : Return metadata blocks or a specific component. invoke(object_id, workflow, params=None) : Trigger a workflow; receives workflow metadata and derived components.","title":"Core operations"},{"location":"client/#usage","text":"from doip_client import StrictDOIPClient client = StrictDOIPClient(host=\"127.0.0.1\", port=3567, use_tls=False) hello = client.hello() ops = client.list_ops() metadata = client.retrieve(\"Q123\").metadata_blocks pdf = client.retrieve(\"Q123\", component=\"doip:bitstream/Q123/main-pdf\") # Invoke a workflow with parameters result = client.invoke(\"Q123\", workflow=\"equation_extraction\", params={\"pages\": [1, 2, 3]})","title":"Usage"},{"location":"client/#tls-verification","text":"Pass use_tls=True to wrap the socket. If you use self-signed certs during development, combine use_tls=True with verify=False to skip hostname verification.","title":"TLS &amp; verification"},{"location":"client/#timeouts-clean-up","text":"The client uses blocking sockets; wrap calls in your own timeout logic if needed. Always close the client when finished: client.close()","title":"Timeouts &amp; clean up"},{"location":"client/#component-handling","text":"For metadata-only requests, send no component and inspect response.metadata_blocks . For binaries, pass the component ID; the client returns ComponentBlock objects containing component_id , media_type , and content bytes.","title":"Component handling"},{"location":"client/#compatibility-listener-support","text":"The Python client speaks strict DOIP. To talk to the compatibility JSON-segment listener ( port + 1 ), use the Client CLI which wraps the same client but performs JSON bridging for you.","title":"Compatibility listener support"},{"location":"client_cli/","text":"The client_cli module provides a minimal command-line interface around the strict DOIP client. Running PYTHONPATH=. python -m client_cli.main --host 127.0.0.1 --port 3567 --no-tls --object-id Q123 Options: - --host : Server host (default 127.0.0.1 ) - --port : Server port (default 3567 ) - --no-tls : Disable TLS wrapping (useful for local plaintext servers) - --insecure : Disable TLS certificate/hostname verification - --object-id : Object identifier to retrieve (default Q123 ) - --action : One of demo , hello , retrieve , invoke (default demo ) - --component : Component ID to retrieve (retrieve/demo actions) - --workflow : Workflow name (invoke action, default equation_extraction ) - --params : Workflow parameters as JSON string (invoke action) - --output : Path or directory to save the first retrieved component (retrieve action) - When saving to a directory, the original filename provided by the server is preserved when present. Actions demo : Runs hello then retrieve . hello : Runs only the hello operation. retrieve : Runs retrieve for the given object (and optional component). invoke : Runs a workflow for the given object with optional params. The CLI prints returned metadata, counts components, and optionally writes the first component to disk for quick smoke testing. Example: download a PDF PYTHONPATH=. python -m client_cli.main --action retrieve --object-id Q6190920 --output . This saves the first returned component to the current directory, honoring the server-provided original filename when available.","title":"Client CLI"},{"location":"client_cli/#running","text":"PYTHONPATH=. python -m client_cli.main --host 127.0.0.1 --port 3567 --no-tls --object-id Q123 Options: - --host : Server host (default 127.0.0.1 ) - --port : Server port (default 3567 ) - --no-tls : Disable TLS wrapping (useful for local plaintext servers) - --insecure : Disable TLS certificate/hostname verification - --object-id : Object identifier to retrieve (default Q123 ) - --action : One of demo , hello , retrieve , invoke (default demo ) - --component : Component ID to retrieve (retrieve/demo actions) - --workflow : Workflow name (invoke action, default equation_extraction ) - --params : Workflow parameters as JSON string (invoke action) - --output : Path or directory to save the first retrieved component (retrieve action) - When saving to a directory, the original filename provided by the server is preserved when present.","title":"Running"},{"location":"client_cli/#actions","text":"demo : Runs hello then retrieve . hello : Runs only the hello operation. retrieve : Runs retrieve for the given object (and optional component). invoke : Runs a workflow for the given object with optional params. The CLI prints returned metadata, counts components, and optionally writes the first component to disk for quick smoke testing.","title":"Actions"},{"location":"client_cli/#example-download-a-pdf","text":"PYTHONPATH=. python -m client_cli.main --action retrieve --object-id Q6190920 --output . This saves the first returned component to the current directory, honoring the server-provided original filename when available.","title":"Example: download a PDF"},{"location":"configuration/","text":"The server builds its configuration by merging config.yaml \u2192 environment variables \u2192 CLI flags . This lets you keep sane defaults in config.yaml , override secrets with env vars, and make temporary changes with flags like --fdo-api . Ports and listeners Binary DOIP listener: defaults to 3567 (set with --port ). Compatibility JSON-segment listener: always runs on port + 1 (default 3568 ). TLS is enabled automatically when both certs/server.crt and certs/server.key exist. Otherwise the listeners stay plaintext. Supported environment variables Variable Purpose FDO_API Base URL of the FDO fa\u00e7ade (e.g., https://fdo.portal.mardi4nfdi.de/fdo/ ). Overrides any value in config.yaml or --fdo-api . LAKEFS_URL lakeFS endpoint, with or without protocol prefix. Normalized to https when missing. LAKEFS_REPO lakeFS repository name used for component lookup. LAKEFS_USER lakeFS access key. LAKEFS_PASSWORD lakeFS secret key. OLLAMA_API_KEY API key passed to the Ollama client when invoking workflows. When set, these variables override matching keys inside config.yaml . config.yaml layout (example) # Simplified template \u2013 replace with your endpoints and credentials ollama: host: localhost port: 11434 use_ssl: false api_key: \"${OLLAMA_API_KEY:-}\" standard_model: qwen2:1.5b timeout: 2 lakefs: url: lake-bioinfmed.zib.de repo: sandbox signature_version: s3v4 user: \"${LAKEFS_USER:-}\" password: \"${LAKEFS_PASSWORD:-}\" Keep secrets in env vars rather than committing them to the template. CLI flags --port : TCP port for the binary listener (compatibility listener uses port+1 ). --fdo-api : Overrides the FDO fa\u00e7ade URL for a single run. Example: start TLS listeners on custom ports using env overrides: export FDO_API=\"https://fdo.example.org/fdo/\" export LAKEFS_URL=\"https://lakefs.internal\" export LAKEFS_USER=\"admin\" LAKEFS_PASSWORD=\"***\" python -m doip_server.main --port 4567 --fdo-api \"$FDO_API\"","title":"Configuration"},{"location":"configuration/#ports-and-listeners","text":"Binary DOIP listener: defaults to 3567 (set with --port ). Compatibility JSON-segment listener: always runs on port + 1 (default 3568 ). TLS is enabled automatically when both certs/server.crt and certs/server.key exist. Otherwise the listeners stay plaintext.","title":"Ports and listeners"},{"location":"configuration/#supported-environment-variables","text":"Variable Purpose FDO_API Base URL of the FDO fa\u00e7ade (e.g., https://fdo.portal.mardi4nfdi.de/fdo/ ). Overrides any value in config.yaml or --fdo-api . LAKEFS_URL lakeFS endpoint, with or without protocol prefix. Normalized to https when missing. LAKEFS_REPO lakeFS repository name used for component lookup. LAKEFS_USER lakeFS access key. LAKEFS_PASSWORD lakeFS secret key. OLLAMA_API_KEY API key passed to the Ollama client when invoking workflows. When set, these variables override matching keys inside config.yaml .","title":"Supported environment variables"},{"location":"configuration/#configyaml-layout-example","text":"# Simplified template \u2013 replace with your endpoints and credentials ollama: host: localhost port: 11434 use_ssl: false api_key: \"${OLLAMA_API_KEY:-}\" standard_model: qwen2:1.5b timeout: 2 lakefs: url: lake-bioinfmed.zib.de repo: sandbox signature_version: s3v4 user: \"${LAKEFS_USER:-}\" password: \"${LAKEFS_PASSWORD:-}\" Keep secrets in env vars rather than committing them to the template.","title":"config.yaml layout (example)"},{"location":"configuration/#cli-flags","text":"--port : TCP port for the binary listener (compatibility listener uses port+1 ). --fdo-api : Overrides the FDO fa\u00e7ade URL for a single run. Example: start TLS listeners on custom ports using env overrides: export FDO_API=\"https://fdo.example.org/fdo/\" export LAKEFS_URL=\"https://lakefs.internal\" export LAKEFS_USER=\"admin\" LAKEFS_PASSWORD=\"***\" python -m doip_server.main --port 4567 --fdo-api \"$FDO_API\"","title":"CLI flags"},{"location":"development/","text":"Local environment Create a venv: python -m venv .venv && source .venv/bin/activate . Install deps: pip install -r requirements.txt (add -e . during active dev). Running tests & quality checks Unit tests: pytest --maxfail=1 --disable-warnings -q Style (if available): ruff check src tests and black src tests Docs workflow Edit pages in docs/content/ and update navigation in docs/mkdocs.yml . Preview locally: cd docs && mkdocs serve --config-file mkdocs.yml Build static site (used for GitHub Pages): cd docs && ./build_docs.sh Project layout The repo keeps runtime code under doip_server/ , doip_client/ , and client_cli/ , with supporting scripts in scripts/ and tests in tests/ . See project_structure.md for a directory tour.","title":"Development"},{"location":"development/#local-environment","text":"Create a venv: python -m venv .venv && source .venv/bin/activate . Install deps: pip install -r requirements.txt (add -e . during active dev).","title":"Local environment"},{"location":"development/#running-tests-quality-checks","text":"Unit tests: pytest --maxfail=1 --disable-warnings -q Style (if available): ruff check src tests and black src tests","title":"Running tests &amp; quality checks"},{"location":"development/#docs-workflow","text":"Edit pages in docs/content/ and update navigation in docs/mkdocs.yml . Preview locally: cd docs && mkdocs serve --config-file mkdocs.yml Build static site (used for GitHub Pages): cd docs && ./build_docs.sh","title":"Docs workflow"},{"location":"development/#project-layout","text":"The repo keeps runtime code under doip_server/ , doip_client/ , and client_cli/ , with supporting scripts in scripts/ and tests in tests/ . See project_structure.md for a directory tour.","title":"Project layout"},{"location":"docker/","text":"Build and run the DOIP server in a container. Build From the project root: docker build -f docker/Dockerfile -t mardi-doip-server . By default the image generates a self-signed cert (CN=localhost) during build. To skip generation, set: docker build -f docker/Dockerfile --build-arg GENERATE_SELF_SIGNED=false -t mardi-doip-server . Run Expose the default DOIP port (plaintext) and the compatibility listener: docker run --rm -p 3567:3567 -p 3568:3568 mardi-doip-server Inject configuration by mounting config.yaml or providing environment variables. Example with env overrides and certificates: docker run --rm \\ -p 3567:3567 -p 3568:3568 \\ -e FDO_API=\"https://fdo.example.org/fdo/\" \\ -e LAKEFS_URL=\"https://lakefs.internal\" \\ -e LAKEFS_USER=admin -e LAKEFS_PASSWORD=secret \\ -v $(pwd)/certs:/app/certs \\ -v $(pwd)/config.yaml:/app/config.yaml:ro \\ mardi-doip-server TLS The server auto-enables TLS when both certs/server.crt and certs/server.key are present. With Docker, mount your certificate directory into /app/certs so the container can detect and load them: docker run --rm -p 3567:3567 -p 3568:3568 \\ -v $(pwd)/certs:/app/certs \\ mardi-doip-server Inside the container, the entrypoint checks for /app/certs/server.crt and /app/certs/server.key and, if found, starts TLS listeners on 3567/3568. Without the mount, the server stays in plaintext mode. The container entrypoint runs python -m doip_server.main .","title":"Docker"},{"location":"docker/#build","text":"From the project root: docker build -f docker/Dockerfile -t mardi-doip-server . By default the image generates a self-signed cert (CN=localhost) during build. To skip generation, set: docker build -f docker/Dockerfile --build-arg GENERATE_SELF_SIGNED=false -t mardi-doip-server .","title":"Build"},{"location":"docker/#run","text":"Expose the default DOIP port (plaintext) and the compatibility listener: docker run --rm -p 3567:3567 -p 3568:3568 mardi-doip-server Inject configuration by mounting config.yaml or providing environment variables. Example with env overrides and certificates: docker run --rm \\ -p 3567:3567 -p 3568:3568 \\ -e FDO_API=\"https://fdo.example.org/fdo/\" \\ -e LAKEFS_URL=\"https://lakefs.internal\" \\ -e LAKEFS_USER=admin -e LAKEFS_PASSWORD=secret \\ -v $(pwd)/certs:/app/certs \\ -v $(pwd)/config.yaml:/app/config.yaml:ro \\ mardi-doip-server","title":"Run"},{"location":"docker/#tls","text":"The server auto-enables TLS when both certs/server.crt and certs/server.key are present. With Docker, mount your certificate directory into /app/certs so the container can detect and load them: docker run --rm -p 3567:3567 -p 3568:3568 \\ -v $(pwd)/certs:/app/certs \\ mardi-doip-server Inside the container, the entrypoint checks for /app/certs/server.crt and /app/certs/server.key and, if found, starts TLS listeners on 3567/3568. Without the mount, the server stays in plaintext mode. The container entrypoint runs python -m doip_server.main .","title":"TLS"},{"location":"project_structure/","text":"doip_server/ : Async DOIP 2.0 server, compatibility listener, and workflow plumbing. doip_client/ : Strict DOIP client helpers for Python callers. client_cli/ : Command-line entry points that wrap the client for demos and smoke tests. docs/ : MkDocs sources ( content/ ), theme config, and build_docs.sh helper. docker/ : Container build context and entrypoint used by docker/Dockerfile . config/ : Sample configuration and environment references. scripts/ : Helper scripts to run server/client locally. tests/ : Pytest suites mirroring the runtime layout.","title":"Project Layout"},{"location":"server/","text":"Overview Asyncio-based TCP server implementing strict DOIP v2.0 framing. Supported operations: - Hello ( 0x01 ) - Retrieve ( 0x02 ) - Invoke ( 0x05 ) - List operations helper ( list_ops ) Two listeners start together: - Binary DOIP: default 3567 (set with --port ). - Compatibility JSON-segment listener: port + 1 (default 3568 ) for doipy-style clients. If certs/server.crt and certs/server.key exist, both listeners start with TLS; otherwise they stay plaintext. Entrypoint Module doip_server.main exposes the CLI and event loop bootstrap. Start the server (plaintext): PYTHONPATH=. python -m doip_server.main --port 3567 CLI flags: - --port : TCP port for the binary listener. - --fdo-api : Override the FDO fa\u00e7ade base URL for the current run. Configuration order of precedence: config.yaml \u2192 environment variables ( FDO_API , LAKEFS_* , OLLAMA_API_KEY ) \u2192 CLI flags. See Configuration for details. Handlers handle_hello Motivation : Allow clients to verify connectivity and discover supported operations without performing data transfers. Use case : A monitoring probe or client bootstrap issues hello to confirm the endpoint is alive and reads the availableOperations map. handle_retrieve Motivation : Deliver FAIR Digital Object bitstreams/components via strict DOIP framing. Use case : A client requests doip:bitstream/Q123/main-pdf to download the canonical PDF for object Q123 ; the handler fetches the bytes from storage and streams component blocks back. handle_invoke Motivation : Trigger server-side workflows that derive new components or metadata from an object. Use case : A client invokes the equation_extraction workflow on Q123 to produce a JSON of extracted equations and receive the derived component and workflow result metadata. handle_list_ops Motivation : Advertise supported operations for discovery. Use case : The client calls list_ops to prime its allowed call set. Protocol Header: >BBBBHI (version, msg type, operation, flags, object ID length, payload length). Blocks: metadata, component, workflow. See doip_server/protocol.py for framing details. Compatibility listener The companion listener on port + 1 accepts doipy-style length-prefixed JSON segments, converts them to DOIP requests, and streams back segments. The first segment is a JSON status block followed by optional component payloads.","title":"Server"},{"location":"server/#overview","text":"Asyncio-based TCP server implementing strict DOIP v2.0 framing. Supported operations: - Hello ( 0x01 ) - Retrieve ( 0x02 ) - Invoke ( 0x05 ) - List operations helper ( list_ops ) Two listeners start together: - Binary DOIP: default 3567 (set with --port ). - Compatibility JSON-segment listener: port + 1 (default 3568 ) for doipy-style clients. If certs/server.crt and certs/server.key exist, both listeners start with TLS; otherwise they stay plaintext.","title":"Overview"},{"location":"server/#entrypoint","text":"Module doip_server.main exposes the CLI and event loop bootstrap. Start the server (plaintext): PYTHONPATH=. python -m doip_server.main --port 3567 CLI flags: - --port : TCP port for the binary listener. - --fdo-api : Override the FDO fa\u00e7ade base URL for the current run. Configuration order of precedence: config.yaml \u2192 environment variables ( FDO_API , LAKEFS_* , OLLAMA_API_KEY ) \u2192 CLI flags. See Configuration for details.","title":"Entrypoint"},{"location":"server/#handlers","text":"handle_hello Motivation : Allow clients to verify connectivity and discover supported operations without performing data transfers. Use case : A monitoring probe or client bootstrap issues hello to confirm the endpoint is alive and reads the availableOperations map. handle_retrieve Motivation : Deliver FAIR Digital Object bitstreams/components via strict DOIP framing. Use case : A client requests doip:bitstream/Q123/main-pdf to download the canonical PDF for object Q123 ; the handler fetches the bytes from storage and streams component blocks back. handle_invoke Motivation : Trigger server-side workflows that derive new components or metadata from an object. Use case : A client invokes the equation_extraction workflow on Q123 to produce a JSON of extracted equations and receive the derived component and workflow result metadata. handle_list_ops Motivation : Advertise supported operations for discovery. Use case : The client calls list_ops to prime its allowed call set.","title":"Handlers"},{"location":"server/#protocol","text":"Header: >BBBBHI (version, msg type, operation, flags, object ID length, payload length). Blocks: metadata, component, workflow. See doip_server/protocol.py for framing details.","title":"Protocol"},{"location":"server/#compatibility-listener","text":"The companion listener on port + 1 accepts doipy-style length-prefixed JSON segments, converts them to DOIP requests, and streams back segments. The first segment is a JSON status block followed by optional component payloads.","title":"Compatibility listener"},{"location":"workflows/","text":"Reproducible Workflows with Snakemake & FDO (Conda-Based) This document outlines the two main processes\u2014 Creation and Execution \u2014for using Snakemake workflows as Fair Digital Objects (FDOs) managed by a DoIP server. This strategy relies on the Conda environment management system to ensure reproducibility across Windows , Linux , and macOS environments without needing Docker or operating system compatibility layers. 1. Target System Preparation (User Role) The User must prepare their local operating system (Windows, Linux, or macOS) by installing the core components necessary to run the Conda-based Snakemake workflow. This setup is required once per machine. Step 1: Prepare the Windows Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. Step 2: Prepare the Linux Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. Step 3: Prepare the macOS Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. 2. Workflow Creation and FDO Registration (Creator Role) The Creator develops a workflow designed for maximum portability and registers the complete package as a persistent FDO artifact. 2.1. Develop the Snakemake Pipeline The workflow must explicitly use the Snakemake Conda integration to ensure cross-platform reproducibility. Write the Snakefile: Define the logic, rules, inputs, and outputs of your pipeline. Define Isolated Environments: For every external tool or dependency, create a dedicated environment.yaml file. These files are crucial as they precisely list the version-locked dependencies (e.g., fastqc=0.11.9 , python=3.9 ). Link Environments in the Snakefile: Ensure every rule points directly to its environment file using the conda: directive. Example Snakefile Snippet: python rule fastqc_report: input: \"data/{sample}.fastq\" output: \"results/{sample}_fastqc.html\" conda: \"envs/fastqc.yaml\" # Links to the environment definition shell: \"fastqc {input} -o {output}\" Test for Portability: Test the workflow on various operating systems (Windows, Linux, macOS) using the --use-conda flag to confirm that the environment files successfully build and the workflow executes identically across platforms. 2.2. Package and Register the FDO The validated workflow files are packaged as a Research Object Crate (RO-Crate) and registered to the DoIP/FDO system. Bundle Artifacts (RO-Crate): Package the Snakefile , all environment.yaml files, configuration files, and a README into a single RO-Crate archive (e.g., a ZIP or TAR archive). Calculate Checksum: Generate a cryptographic hash (e.g., SHA-256) of the final RO-Crate archive. Store and Mint PID: Upload the RO-Crate to the durable storage system. The automated registration service calls the DoIP server to mint a new PID . The PID's resolution data must store the storage URL and the Checksum . Register FDO: Submit the complete FDO metadata (PID, creator, description, input parameters, checksum , and dependency list) to the FDO Registry . 3. Workflow Execution (User Role) The User executes the verified, reproducible workflow on their local machine using the PID and local Conda installation. 3.1. Execute the FDO Client The FDO client automates the download, verification, and Snakemake execution steps. Initiate Run: The User executes the workflow using its PID and specifies the local input data directory. Example Command (Windows): bash fdo-run-client 20.500.12345/workflow_A01 --input \"C:\\User\\Data\\RawSequences\" --cores 4 Client Verification Logic: The client handles the critical, verifiable steps programmatically: * Resolve PID: Queries the DoIP server to retrieve the Storage URL and the original Checksum. * Download & Extract: Downloads the RO-Crate and extracts it to a temporary working directory. * Verify Integrity: Calculates the checksum of the downloaded file. Execution stops if this value does not match the PID's original checksum. * Prepare: Maps the user's input directory into the Snakemake configuration. Snakemake Execution: The client initiates the Snakemake run command: bash snakemake -s /path/to/Snakefile --cores 4 --use-conda --config input_path=\"/path/to/input/data\" 3.2. Guaranteed Reproducibility Across OS Because the --use-conda flag is employed: Snakemake reads the environment.yaml files within the downloaded RO-Crate. Conda automatically creates temporary, isolated software environments with the exact, version-locked dependencies compiled for the User's specific OS (Windows, Linux, or macOS). The workflow runs identically across all supported platforms, achieving high-fidelity reproducibility without external virtualization layers.","title":"Workflows"},{"location":"workflows/#reproducible-workflows-with-snakemake-fdo-conda-based","text":"This document outlines the two main processes\u2014 Creation and Execution \u2014for using Snakemake workflows as Fair Digital Objects (FDOs) managed by a DoIP server. This strategy relies on the Conda environment management system to ensure reproducibility across Windows , Linux , and macOS environments without needing Docker or operating system compatibility layers.","title":"Reproducible Workflows with Snakemake &amp; FDO (Conda-Based)"},{"location":"workflows/#1-target-system-preparation-user-role","text":"The User must prepare their local operating system (Windows, Linux, or macOS) by installing the core components necessary to run the Conda-based Snakemake workflow. This setup is required once per machine.","title":"1. Target System Preparation (User Role)"},{"location":"workflows/#step-1-prepare-the-windows-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 1: Prepare the Windows Environment"},{"location":"workflows/#step-2-prepare-the-linux-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 2: Prepare the Linux Environment"},{"location":"workflows/#step-3-prepare-the-macos-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 3: Prepare the macOS Environment"},{"location":"workflows/#2-workflow-creation-and-fdo-registration-creator-role","text":"The Creator develops a workflow designed for maximum portability and registers the complete package as a persistent FDO artifact.","title":"2. Workflow Creation and FDO Registration (Creator Role)"},{"location":"workflows/#21-develop-the-snakemake-pipeline","text":"The workflow must explicitly use the Snakemake Conda integration to ensure cross-platform reproducibility. Write the Snakefile: Define the logic, rules, inputs, and outputs of your pipeline. Define Isolated Environments: For every external tool or dependency, create a dedicated environment.yaml file. These files are crucial as they precisely list the version-locked dependencies (e.g., fastqc=0.11.9 , python=3.9 ). Link Environments in the Snakefile: Ensure every rule points directly to its environment file using the conda: directive. Example Snakefile Snippet: python rule fastqc_report: input: \"data/{sample}.fastq\" output: \"results/{sample}_fastqc.html\" conda: \"envs/fastqc.yaml\" # Links to the environment definition shell: \"fastqc {input} -o {output}\" Test for Portability: Test the workflow on various operating systems (Windows, Linux, macOS) using the --use-conda flag to confirm that the environment files successfully build and the workflow executes identically across platforms.","title":"2.1. Develop the Snakemake Pipeline"},{"location":"workflows/#22-package-and-register-the-fdo","text":"The validated workflow files are packaged as a Research Object Crate (RO-Crate) and registered to the DoIP/FDO system. Bundle Artifacts (RO-Crate): Package the Snakefile , all environment.yaml files, configuration files, and a README into a single RO-Crate archive (e.g., a ZIP or TAR archive). Calculate Checksum: Generate a cryptographic hash (e.g., SHA-256) of the final RO-Crate archive. Store and Mint PID: Upload the RO-Crate to the durable storage system. The automated registration service calls the DoIP server to mint a new PID . The PID's resolution data must store the storage URL and the Checksum . Register FDO: Submit the complete FDO metadata (PID, creator, description, input parameters, checksum , and dependency list) to the FDO Registry .","title":"2.2. Package and Register the FDO"},{"location":"workflows/#3-workflow-execution-user-role","text":"The User executes the verified, reproducible workflow on their local machine using the PID and local Conda installation.","title":"3. Workflow Execution (User Role)"},{"location":"workflows/#31-execute-the-fdo-client","text":"The FDO client automates the download, verification, and Snakemake execution steps. Initiate Run: The User executes the workflow using its PID and specifies the local input data directory. Example Command (Windows): bash fdo-run-client 20.500.12345/workflow_A01 --input \"C:\\User\\Data\\RawSequences\" --cores 4 Client Verification Logic: The client handles the critical, verifiable steps programmatically: * Resolve PID: Queries the DoIP server to retrieve the Storage URL and the original Checksum. * Download & Extract: Downloads the RO-Crate and extracts it to a temporary working directory. * Verify Integrity: Calculates the checksum of the downloaded file. Execution stops if this value does not match the PID's original checksum. * Prepare: Maps the user's input directory into the Snakemake configuration. Snakemake Execution: The client initiates the Snakemake run command: bash snakemake -s /path/to/Snakefile --cores 4 --use-conda --config input_path=\"/path/to/input/data\"","title":"3.1. Execute the FDO Client"},{"location":"workflows/#32-guaranteed-reproducibility-across-os","text":"Because the --use-conda flag is employed: Snakemake reads the environment.yaml files within the downloaded RO-Crate. Conda automatically creates temporary, isolated software environments with the exact, version-locked dependencies compiled for the User's specific OS (Windows, Linux, or macOS). The workflow runs identically across all supported platforms, achieving high-fidelity reproducibility without external virtualization layers.","title":"3.2. Guaranteed Reproducibility Across OS"}]}