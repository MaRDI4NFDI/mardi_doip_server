{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Strict DOIP v2.0 implementation for FAIR Digital Objects (FDOs), backed by lakeFS storage and an FDO fa\u00e7ade. This site covers how to run the server, call it from Python or the CLI, configure TLS, and build the Docker image. Why DOIP and FDO? FAIR Digital Objects (FDOs) provide persistent identifiers plus structured metadata and component links, improving interoperability and long-term access. Digital Object Interface Protocol (DOIP) standardizes how to fetch and operate on those objects over the network using binary envelopes and operation codes. This project supplies both sides\u2014server and client\u2014so MaRDI services can publish and consume FDO content (bitstreams, derived components, workflow results) consistently. Capabilities at a glance Binary DOIP listener on TCP ( 3567 by default) with automatic TLS when certs/server.crt and certs/server.key exist. Compatibility JSON-segment listener on port + 1 ( 3568 by default) for doipy-style clients. Operations: hello , retrieve , invoke , plus a list_ops helper. lakeFS-backed component retrieval and workflow-driven derived components. Quick start 1) Start the server (plaintext example): PYTHONPATH=. python -m doip_server.main --port 3567 2) Retrieve an object with the CLI: PYTHONPATH=. python -m client_cli.main \\ --host 127.0.0.1 --port 3567 --no-tls \\ --action retrieve --object-id Q6190920 --output . The CLI issues hello then retrieve , prints returned metadata, and saves the first component using the server-provided filename when available. See Configuration to point the server at your lakeFS and FDO endpoints, and Docker for containerized runs.","title":"Home"},{"location":"#why-doip-and-fdo","text":"FAIR Digital Objects (FDOs) provide persistent identifiers plus structured metadata and component links, improving interoperability and long-term access. Digital Object Interface Protocol (DOIP) standardizes how to fetch and operate on those objects over the network using binary envelopes and operation codes. This project supplies both sides\u2014server and client\u2014so MaRDI services can publish and consume FDO content (bitstreams, derived components, workflow results) consistently.","title":"Why DOIP and FDO?"},{"location":"#capabilities-at-a-glance","text":"Binary DOIP listener on TCP ( 3567 by default) with automatic TLS when certs/server.crt and certs/server.key exist. Compatibility JSON-segment listener on port + 1 ( 3568 by default) for doipy-style clients. Operations: hello , retrieve , invoke , plus a list_ops helper. lakeFS-backed component retrieval and workflow-driven derived components.","title":"Capabilities at a glance"},{"location":"#quick-start","text":"1) Start the server (plaintext example): PYTHONPATH=. python -m doip_server.main --port 3567 2) Retrieve an object with the CLI: PYTHONPATH=. python -m client_cli.main \\ --host 127.0.0.1 --port 3567 --no-tls \\ --action retrieve --object-id Q6190920 --output . The CLI issues hello then retrieve , prints returned metadata, and saves the first component using the server-provided filename when available. See Configuration to point the server at your lakeFS and FDO endpoints, and Docker for containerized runs.","title":"Quick start"},{"location":"client/","text":"doip_client implements a strict DOIP v2.0 client that mirrors the server framing (binary envelope, metadata/component/workflow blocks) and supports TLS. Core operations hello() : Health check and capability discovery. list_ops() : Fetch the availableOperations map. retrieve(object_id, component=None) : Return metadata blocks or a specific component. invoke(object_id, workflow, params=None) : Trigger a workflow; receives workflow metadata and derived components. Usage from doip_client import StrictDOIPClient client = StrictDOIPClient(host=\"127.0.0.1\", port=3567, use_tls=False) hello = client.hello() ops = client.list_ops() metadata = client.retrieve(\"Q123\").metadata_blocks pdf = client.retrieve(\"Q123\", component=\"doip:bitstream/Q123/main-pdf\") # Invoke a workflow with parameters result = client.invoke(\"Q123\", workflow=\"equation_extraction\", params={\"pages\": [1, 2, 3]}) TLS & verification Pass use_tls=True to wrap the socket. If you use self-signed certs during development, combine use_tls=True with verify=False to skip hostname verification. Timeouts & clean up The client uses blocking sockets; wrap calls in your own timeout logic if needed. Always close the client when finished: client.close() Component handling For metadata-only requests, send no component and inspect response.metadata_blocks . For binaries, pass the component ID; the client returns ComponentBlock objects containing component_id , media_type , and content bytes. Compatibility listener support The Python client speaks strict DOIP. To talk to the compatibility JSON-segment listener ( port + 1 ), use the Client CLI which wraps the same client but performs JSON bridging for you.","title":"Client"},{"location":"client/#core-operations","text":"hello() : Health check and capability discovery. list_ops() : Fetch the availableOperations map. retrieve(object_id, component=None) : Return metadata blocks or a specific component. invoke(object_id, workflow, params=None) : Trigger a workflow; receives workflow metadata and derived components.","title":"Core operations"},{"location":"client/#usage","text":"from doip_client import StrictDOIPClient client = StrictDOIPClient(host=\"127.0.0.1\", port=3567, use_tls=False) hello = client.hello() ops = client.list_ops() metadata = client.retrieve(\"Q123\").metadata_blocks pdf = client.retrieve(\"Q123\", component=\"doip:bitstream/Q123/main-pdf\") # Invoke a workflow with parameters result = client.invoke(\"Q123\", workflow=\"equation_extraction\", params={\"pages\": [1, 2, 3]})","title":"Usage"},{"location":"client/#tls-verification","text":"Pass use_tls=True to wrap the socket. If you use self-signed certs during development, combine use_tls=True with verify=False to skip hostname verification.","title":"TLS &amp; verification"},{"location":"client/#timeouts-clean-up","text":"The client uses blocking sockets; wrap calls in your own timeout logic if needed. Always close the client when finished: client.close()","title":"Timeouts &amp; clean up"},{"location":"client/#component-handling","text":"For metadata-only requests, send no component and inspect response.metadata_blocks . For binaries, pass the component ID; the client returns ComponentBlock objects containing component_id , media_type , and content bytes.","title":"Component handling"},{"location":"client/#compatibility-listener-support","text":"The Python client speaks strict DOIP. To talk to the compatibility JSON-segment listener ( port + 1 ), use the Client CLI which wraps the same client but performs JSON bridging for you.","title":"Compatibility listener support"},{"location":"client_cli/","text":"The client_cli module provides a minimal command-line interface around the DOIP client. Running PYTHONPATH=. python -m client_cli.main --object-id Q123 --action retrieve Options: - --host : DOIP server host (default doip.staging.mardi4nfdi.org ) - --port : DOIP server port (default 3567 ) - --no-tls : Disable TLS wrapping (useful for local plaintext servers) - --insecure : Disable TLS certificate/hostname verification - --object-id : Object identifier to retrieve (default Q123 ) - --action : One of demo , hello , retrieve , invoke (default demo ) - --component : Component ID to retrieve (retrieve/demo actions) - --workflow : Workflow name (invoke action, default equation_extraction ) - --params : Workflow parameters as JSON string (invoke action) - --output : Path or directory to save the first retrieved component (retrieve action) - When saving to a directory, the original filename provided by the server is preserved when present. Actions demo : Runs hello then retrieve . hello : Runs only the hello operation. retrieve : Runs retrieve for the given object (and optional component). invoke : Runs a workflow for the given object with optional params. Example: Download a PDF PYTHONPATH=. python -m client_cli.main --action retrieve --object-id Q6190920 --component fulltext --output .","title":"Client CLI"},{"location":"client_cli/#running","text":"PYTHONPATH=. python -m client_cli.main --object-id Q123 --action retrieve Options: - --host : DOIP server host (default doip.staging.mardi4nfdi.org ) - --port : DOIP server port (default 3567 ) - --no-tls : Disable TLS wrapping (useful for local plaintext servers) - --insecure : Disable TLS certificate/hostname verification - --object-id : Object identifier to retrieve (default Q123 ) - --action : One of demo , hello , retrieve , invoke (default demo ) - --component : Component ID to retrieve (retrieve/demo actions) - --workflow : Workflow name (invoke action, default equation_extraction ) - --params : Workflow parameters as JSON string (invoke action) - --output : Path or directory to save the first retrieved component (retrieve action) - When saving to a directory, the original filename provided by the server is preserved when present.","title":"Running"},{"location":"client_cli/#actions","text":"demo : Runs hello then retrieve . hello : Runs only the hello operation. retrieve : Runs retrieve for the given object (and optional component). invoke : Runs a workflow for the given object with optional params.","title":"Actions"},{"location":"client_cli/#example-download-a-pdf","text":"PYTHONPATH=. python -m client_cli.main --action retrieve --object-id Q6190920 --component fulltext --output .","title":"Example: Download a PDF"},{"location":"configuration/","text":"The server builds its configuration by merging config.yaml \u2192 environment variables \u2192 CLI flags . This lets you keep sane defaults in config.yaml , override secrets with env vars, and make temporary changes with flags like --fdo-api . Ports and listeners Binary DOIP listener: defaults to 3567 (set with --port ). Compatibility JSON-segment listener: always runs on port + 1 (default 3568 ). TLS is enabled automatically when both certs/server.crt and certs/server.key exist. Otherwise the listeners stay plaintext. Supported environment variables Variable Purpose FDO_API Base URL of the FDO fa\u00e7ade (e.g., https://fdo.portal.mardi4nfdi.de/fdo/ ). Overrides any value in config.yaml or --fdo-api . LAKEFS_URL lakeFS endpoint, with or without protocol prefix. Normalized to https when missing. LAKEFS_REPO lakeFS repository name used for component lookup. LAKEFS_USER lakeFS access key. LAKEFS_PASSWORD lakeFS secret key. OLLAMA_API_KEY API key passed to the Ollama client when invoking workflows. When set, these variables override matching keys inside config.yaml . config.yaml layout (example) # Simplified template \u2013 replace with your endpoints and credentials ollama: host: localhost port: 11434 use_ssl: false api_key: \"${OLLAMA_API_KEY:-}\" standard_model: qwen2:1.5b timeout: 2 lakefs: url: lake-bioinfmed.zib.de repo: sandbox signature_version: s3v4 user: \"${LAKEFS_USER:-}\" password: \"${LAKEFS_PASSWORD:-}\" Keep secrets in env vars rather than committing them to the template. CLI flags --port : TCP port for the binary listener (compatibility listener uses port+1 ). --fdo-api : Overrides the FDO fa\u00e7ade URL for a single run. Example: start TLS listeners on custom ports using env overrides: export FDO_API=\"https://fdo.example.org/fdo/\" export LAKEFS_URL=\"https://lakefs.internal\" export LAKEFS_USER=\"admin\" LAKEFS_PASSWORD=\"***\" python -m doip_server.main --port 4567 --fdo-api \"$FDO_API\"","title":"Configuration"},{"location":"configuration/#ports-and-listeners","text":"Binary DOIP listener: defaults to 3567 (set with --port ). Compatibility JSON-segment listener: always runs on port + 1 (default 3568 ). TLS is enabled automatically when both certs/server.crt and certs/server.key exist. Otherwise the listeners stay plaintext.","title":"Ports and listeners"},{"location":"configuration/#supported-environment-variables","text":"Variable Purpose FDO_API Base URL of the FDO fa\u00e7ade (e.g., https://fdo.portal.mardi4nfdi.de/fdo/ ). Overrides any value in config.yaml or --fdo-api . LAKEFS_URL lakeFS endpoint, with or without protocol prefix. Normalized to https when missing. LAKEFS_REPO lakeFS repository name used for component lookup. LAKEFS_USER lakeFS access key. LAKEFS_PASSWORD lakeFS secret key. OLLAMA_API_KEY API key passed to the Ollama client when invoking workflows. When set, these variables override matching keys inside config.yaml .","title":"Supported environment variables"},{"location":"configuration/#configyaml-layout-example","text":"# Simplified template \u2013 replace with your endpoints and credentials ollama: host: localhost port: 11434 use_ssl: false api_key: \"${OLLAMA_API_KEY:-}\" standard_model: qwen2:1.5b timeout: 2 lakefs: url: lake-bioinfmed.zib.de repo: sandbox signature_version: s3v4 user: \"${LAKEFS_USER:-}\" password: \"${LAKEFS_PASSWORD:-}\" Keep secrets in env vars rather than committing them to the template.","title":"config.yaml layout (example)"},{"location":"configuration/#cli-flags","text":"--port : TCP port for the binary listener (compatibility listener uses port+1 ). --fdo-api : Overrides the FDO fa\u00e7ade URL for a single run. Example: start TLS listeners on custom ports using env overrides: export FDO_API=\"https://fdo.example.org/fdo/\" export LAKEFS_URL=\"https://lakefs.internal\" export LAKEFS_USER=\"admin\" LAKEFS_PASSWORD=\"***\" python -m doip_server.main --port 4567 --fdo-api \"$FDO_API\"","title":"CLI flags"},{"location":"development/","text":"Local environment Create a venv: python -m venv .venv && source .venv/bin/activate . Install deps: pip install -r requirements.txt (add -e . during active dev). Running tests & quality checks Unit tests: pytest --maxfail=1 --disable-warnings -q Style (if available): ruff check src tests and black src tests Docs workflow Edit pages in docs/content/ and update navigation in docs/mkdocs.yml . Preview locally: cd docs && mkdocs serve --config-file mkdocs.yml Build static site (used for GitHub Pages): cd docs && ./build_docs.sh Project layout The repo keeps runtime code under doip_server/ , doip_client/ , and client_cli/ , with supporting scripts in scripts/ and tests in tests/ . See project_structure.md for a directory tour.","title":"Development"},{"location":"development/#local-environment","text":"Create a venv: python -m venv .venv && source .venv/bin/activate . Install deps: pip install -r requirements.txt (add -e . during active dev).","title":"Local environment"},{"location":"development/#running-tests-quality-checks","text":"Unit tests: pytest --maxfail=1 --disable-warnings -q Style (if available): ruff check src tests and black src tests","title":"Running tests &amp; quality checks"},{"location":"development/#docs-workflow","text":"Edit pages in docs/content/ and update navigation in docs/mkdocs.yml . Preview locally: cd docs && mkdocs serve --config-file mkdocs.yml Build static site (used for GitHub Pages): cd docs && ./build_docs.sh","title":"Docs workflow"},{"location":"development/#project-layout","text":"The repo keeps runtime code under doip_server/ , doip_client/ , and client_cli/ , with supporting scripts in scripts/ and tests in tests/ . See project_structure.md for a directory tour.","title":"Project layout"},{"location":"docker/","text":"Build and run the DOIP server in a container. Build From the project root: docker build -f docker/Dockerfile -t mardi-doip-server . By default the image generates a self-signed cert (CN=localhost) during build. To skip generation, set: docker build -f docker/Dockerfile --build-arg GENERATE_SELF_SIGNED=false -t mardi-doip-server . Run Expose the default DOIP port (plaintext) and the compatibility listener: docker run --rm -p 3567:3567 -p 3568:3568 mardi-doip-server Inject configuration by mounting config.yaml or providing environment variables. Example with env overrides and certificates: docker run --rm \\ -p 3567:3567 -p 3568:3568 \\ -e FDO_API=\"https://fdo.example.org/fdo/\" \\ -e LAKEFS_URL=\"https://lakefs.internal\" \\ -e LAKEFS_USER=admin -e LAKEFS_PASSWORD=secret \\ -v $(pwd)/certs:/app/certs \\ -v $(pwd)/config.yaml:/app/config.yaml:ro \\ mardi-doip-server TLS The server auto-enables TLS when both certs/server.crt and certs/server.key are present. With Docker, mount your certificate directory into /app/certs so the container can detect and load them: docker run --rm -p 3567:3567 -p 3568:3568 \\ -v $(pwd)/certs:/app/certs \\ mardi-doip-server Inside the container, the entrypoint checks for /app/certs/server.crt and /app/certs/server.key and, if found, starts TLS listeners on 3567/3568. Without the mount, the server stays in plaintext mode. The container entrypoint runs python -m doip_server.main .","title":"Docker"},{"location":"docker/#build","text":"From the project root: docker build -f docker/Dockerfile -t mardi-doip-server . By default the image generates a self-signed cert (CN=localhost) during build. To skip generation, set: docker build -f docker/Dockerfile --build-arg GENERATE_SELF_SIGNED=false -t mardi-doip-server .","title":"Build"},{"location":"docker/#run","text":"Expose the default DOIP port (plaintext) and the compatibility listener: docker run --rm -p 3567:3567 -p 3568:3568 mardi-doip-server Inject configuration by mounting config.yaml or providing environment variables. Example with env overrides and certificates: docker run --rm \\ -p 3567:3567 -p 3568:3568 \\ -e FDO_API=\"https://fdo.example.org/fdo/\" \\ -e LAKEFS_URL=\"https://lakefs.internal\" \\ -e LAKEFS_USER=admin -e LAKEFS_PASSWORD=secret \\ -v $(pwd)/certs:/app/certs \\ -v $(pwd)/config.yaml:/app/config.yaml:ro \\ mardi-doip-server","title":"Run"},{"location":"docker/#tls","text":"The server auto-enables TLS when both certs/server.crt and certs/server.key are present. With Docker, mount your certificate directory into /app/certs so the container can detect and load them: docker run --rm -p 3567:3567 -p 3568:3568 \\ -v $(pwd)/certs:/app/certs \\ mardi-doip-server Inside the container, the entrypoint checks for /app/certs/server.crt and /app/certs/server.key and, if found, starts TLS listeners on 3567/3568. Without the mount, the server stays in plaintext mode. The container entrypoint runs python -m doip_server.main .","title":"TLS"},{"location":"project_structure/","text":"doip_server/ : Async DOIP 2.0 server, compatibility listener, and workflow plumbing. doip_client/ : Strict DOIP client helpers for Python callers. client_cli/ : Command-line entry points that wrap the client for demos and smoke tests. docs/ : MkDocs sources ( content/ ), theme config, and build_docs.sh helper. docker/ : Container build context and entrypoint used by docker/Dockerfile . config/ : Sample configuration and environment references. scripts/ : Helper scripts to run server/client locally. tests/ : Pytest suites mirroring the runtime layout.","title":"Project Layout"},{"location":"server/","text":"Overview Asyncio-based TCP server implementing strict DOIP v2.0 framing. Supported operations: - Hello ( 0x01 ) - Retrieve ( 0x02 ) - Invoke ( 0x05 ) - List operations helper ( list_ops ) Two listeners start together: - Binary DOIP: default 3567 (set with --port ). - Compatibility JSON-segment listener: port + 1 (default 3568 ) for doipy-style clients. If certs/server.crt and certs/server.key exist, both listeners start with TLS; otherwise they stay plaintext. Entrypoint Module doip_server.main exposes the CLI and event loop bootstrap. Start the server (plaintext): PYTHONPATH=. python -m doip_server.main --port 3567 CLI flags: - --port : TCP port for the binary listener. - --fdo-api : Override the FDO fa\u00e7ade base URL for the current run. Configuration order of precedence: config.yaml \u2192 environment variables ( FDO_API , LAKEFS_* , OLLAMA_API_KEY ) \u2192 CLI flags. See Configuration for details. Handlers handle_hello Motivation : Allow clients to verify connectivity and discover supported operations without performing data transfers. Use case : A monitoring probe or client bootstrap issues hello to confirm the endpoint is alive and reads the availableOperations map. handle_retrieve Motivation : Deliver FAIR Digital Object bitstreams/components via strict DOIP framing. Use case : A client requests doip:bitstream/Q123/main-pdf to download the canonical PDF for object Q123 ; the handler fetches the bytes from storage and streams component blocks back. handle_invoke Motivation : Trigger server-side workflows that derive new components or metadata from an object. Use case : A client invokes the equation_extraction workflow on Q123 to produce a JSON of extracted equations and receive the derived component and workflow result metadata. handle_list_ops Motivation : Advertise supported operations for discovery. Use case : The client calls list_ops to prime its allowed call set. Protocol Header: >BBBBHI (version, msg type, operation, flags, object ID length, payload length). Blocks: metadata, component, workflow. See doip_server/protocol.py for framing details. Compatibility listener The companion listener on port + 1 accepts doipy-style length-prefixed JSON segments, converts them to DOIP requests, and streams back segments. The first segment is a JSON status block followed by optional component payloads.","title":"Server"},{"location":"server/#overview","text":"Asyncio-based TCP server implementing strict DOIP v2.0 framing. Supported operations: - Hello ( 0x01 ) - Retrieve ( 0x02 ) - Invoke ( 0x05 ) - List operations helper ( list_ops ) Two listeners start together: - Binary DOIP: default 3567 (set with --port ). - Compatibility JSON-segment listener: port + 1 (default 3568 ) for doipy-style clients. If certs/server.crt and certs/server.key exist, both listeners start with TLS; otherwise they stay plaintext.","title":"Overview"},{"location":"server/#entrypoint","text":"Module doip_server.main exposes the CLI and event loop bootstrap. Start the server (plaintext): PYTHONPATH=. python -m doip_server.main --port 3567 CLI flags: - --port : TCP port for the binary listener. - --fdo-api : Override the FDO fa\u00e7ade base URL for the current run. Configuration order of precedence: config.yaml \u2192 environment variables ( FDO_API , LAKEFS_* , OLLAMA_API_KEY ) \u2192 CLI flags. See Configuration for details.","title":"Entrypoint"},{"location":"server/#handlers","text":"handle_hello Motivation : Allow clients to verify connectivity and discover supported operations without performing data transfers. Use case : A monitoring probe or client bootstrap issues hello to confirm the endpoint is alive and reads the availableOperations map. handle_retrieve Motivation : Deliver FAIR Digital Object bitstreams/components via strict DOIP framing. Use case : A client requests doip:bitstream/Q123/main-pdf to download the canonical PDF for object Q123 ; the handler fetches the bytes from storage and streams component blocks back. handle_invoke Motivation : Trigger server-side workflows that derive new components or metadata from an object. Use case : A client invokes the equation_extraction workflow on Q123 to produce a JSON of extracted equations and receive the derived component and workflow result metadata. handle_list_ops Motivation : Advertise supported operations for discovery. Use case : The client calls list_ops to prime its allowed call set.","title":"Handlers"},{"location":"server/#protocol","text":"Header: >BBBBHI (version, msg type, operation, flags, object ID length, payload length). Blocks: metadata, component, workflow. See doip_server/protocol.py for framing details.","title":"Protocol"},{"location":"server/#compatibility-listener","text":"The companion listener on port + 1 accepts doipy-style length-prefixed JSON segments, converts them to DOIP requests, and streams back segments. The first segment is a JSON status block followed by optional component payloads.","title":"Compatibility listener"},{"location":"server_http_gateway/","text":"This component provides a thin HTTP layer that forwards browser-friendly download requests to the internal DOIP server. It is served by FastAPI in doip_server/http_gateway.py and is intended for environments where a simple REST-style endpoint is preferred over the native DOIP protocol. Endpoint GET /doip/retrieve/{object_id}/{component_id} Streams the first matching component block for the given object/component pair. Sets Content-Type from the component's media_type (defaults to application/octet-stream ). Adds Content-Disposition: attachment; filename=\"<component_id_basename>\" so browsers download instead of render. Returns 404 if no component blocks are present; 502 for backend failures. Example curl -OJ http://localhost/doip/retrieve/Q123/fulltext Backend connection The gateway talks to the colocated DOIP server through StrictDOIPClient using these environment variables: DOIP_HOST (default 127.0.0.1 ): hostname for the DOIP TCP endpoint; values like tcp://host:port are accepted. DOIP_PORT (default 3567 ): port number; also parsed from tcp:// or host:port forms. DOIP_VERIFY_TLS (default false ): set to true to enable certificate verification when TLS is active. TLS is automatically enabled when certs/server.crt exists alongside the gateway image; override by setting use_tls in code or removing the cert. Static assets The root path / serves the legacy landing page and associated assets from /app/landing using FastAPI's StaticFiles mount. This keeps the former download UI available without the DOIP protocol in the browser. Running locally The Docker entrypoint starts the gateway with Uvicorn: uvicorn doip_server.http_gateway:app --host 0.0.0.0 --port 80 For development you can run the same command from the repository root (inside an activated virtualenv) and then issue the curl example above.","title":"Server HTTP Gateway"},{"location":"server_http_gateway/#endpoint","text":"GET /doip/retrieve/{object_id}/{component_id} Streams the first matching component block for the given object/component pair. Sets Content-Type from the component's media_type (defaults to application/octet-stream ). Adds Content-Disposition: attachment; filename=\"<component_id_basename>\" so browsers download instead of render. Returns 404 if no component blocks are present; 502 for backend failures.","title":"Endpoint"},{"location":"server_http_gateway/#example","text":"curl -OJ http://localhost/doip/retrieve/Q123/fulltext","title":"Example"},{"location":"server_http_gateway/#backend-connection","text":"The gateway talks to the colocated DOIP server through StrictDOIPClient using these environment variables: DOIP_HOST (default 127.0.0.1 ): hostname for the DOIP TCP endpoint; values like tcp://host:port are accepted. DOIP_PORT (default 3567 ): port number; also parsed from tcp:// or host:port forms. DOIP_VERIFY_TLS (default false ): set to true to enable certificate verification when TLS is active. TLS is automatically enabled when certs/server.crt exists alongside the gateway image; override by setting use_tls in code or removing the cert.","title":"Backend connection"},{"location":"server_http_gateway/#static-assets","text":"The root path / serves the legacy landing page and associated assets from /app/landing using FastAPI's StaticFiles mount. This keeps the former download UI available without the DOIP protocol in the browser.","title":"Static assets"},{"location":"server_http_gateway/#running-locally","text":"The Docker entrypoint starts the gateway with Uvicorn: uvicorn doip_server.http_gateway:app --host 0.0.0.0 --port 80 For development you can run the same command from the repository root (inside an activated virtualenv) and then issue the curl example above.","title":"Running locally"},{"location":"workflow_example/","text":"This reproducible workflow requires three main files to be included in your FDO (RO-Crate): the data input, the Conda environment definition, the Octave script, and the Snakemake pipeline itself. 1. The Input Data (data/matrix.csv) 1.0, 0.5, 0.2 0.5, 2.0, 0.3 0.2, 0.3, 3.0 2. Conda Environment (envs/octave_analysis.yaml) channels: - conda-forge dependencies: - octave=6.4.0 - python=3.9 - pandas=1.3 - matplotlib=3.4 3. Octave Script (scripts/eigen_analysis.m) % scripts/eigen_analysis.m input_file = argv(){1}; output_file = argv(){2}; M = csvread(input_file); [V, D] = eig(M); eigenvalues = diag(D); csvwrite(output_file, eigenvalues); disp(\"Octave analysis complete. Eigenvalues saved.\"); 4. Snakemake Pipeline (Snakefile) configfile: \"config.yaml\" rule all: input: \"results/eigenvalues_plot.png\" rule compute_eigenvalues: input: \"data/matrix.csv\" output: \"results/eigenvalues.csv\" params: octave_script = \"scripts/eigen_analysis.m\" conda: \"envs/octave_analysis.yaml\" shell: \"octave --no-gui --silent {params.octave_script} {input} {output}\" rule plot_eigenvalues: input: \"results/eigenvalues.csv\" output: \"results/eigenvalues_plot.png\" params: plot_script = \"scripts/plot_eigenvalues.py\" conda: \"envs/octave_analysis.yaml\" script: ''' import pandas as pd import matplotlib.pyplot as plt import numpy as np eigenvalues = pd.read_csv( snakemake.input[0], header=None ).values eigenvalues = np.sort(eigenvalues) plt.figure(figsize=(8, 6)) plt.bar( range(1, len(eigenvalues) + 1), eigenvalues ) plt.xlabel('Eigenvalue Index') plt.ylabel('Eigenvalue Magnitude') plt.title('Eigenvalues of the 3x3 Matrix') plt.xticks(range(1, 4)) plt.grid(axis='y') plt.savefig(snakemake.output[0]) print(snakemake.output[0]) ''' Summary of Execution (PID to Plot) This summary details the entire automated process, from the user providing the Persistent Identifier (PID) to the final plot generation, ensuring the role of the DoIP/FDO system is clearly represented. PID Resolution & Retrieval: The user initiates the run via the FDO Client using the workflow's PID. The FDO Client queries the DoIP server to resolve the PID, retrieving the RO-Crate's storage URL and its original Checksum . The Client downloads the RO-Crate archive (containing the Snakefile , envs/ , scripts/ , etc.) and extracts the contents to a temporary local directory. Integrity Verification: The Client calculates a new checksum of the downloaded RO-Crate and compares it to the value retrieved from the DoIP server. Execution proceeds only if the checksums match , guaranteeing the integrity and reproducibility of the workflow artifact. Snakemake Orchestration: The Client calls the local snakemake --use-conda command within the temporary directory. Rule 1: compute_eigenvalues (Octave): Conda creates the isolated environment containing the specified version of Octave . The rule executes the Octave script ( scripts/eigen_analysis.m ). Octave reads the input matrix and saves the computed eigenvalues to the intermediate file, results/eigenvalues.csv . Rule 2: plot_eigenvalues (Python/Matplotlib): Snakemake uses the same Conda environment (which contains Python, Pandas, and Matplotlib). The Python script reads the results/eigenvalues.csv file. It generates the bar plot visualization and saves the final result as results/eigenvalues_plot.png . Cleanup and Output: The workflow finishes, and the FDO Client presents the final output file(s) to the user. The Client performs cleanup, removing the temporary directory and the created Conda environments.","title":"Workflow example"},{"location":"workflow_example/#1-the-input-data-datamatrixcsv","text":"1.0, 0.5, 0.2 0.5, 2.0, 0.3 0.2, 0.3, 3.0","title":"1. The Input Data (data/matrix.csv)"},{"location":"workflow_example/#2-conda-environment-envsoctave_analysisyaml","text":"channels: - conda-forge dependencies: - octave=6.4.0 - python=3.9 - pandas=1.3 - matplotlib=3.4","title":"2. Conda Environment (envs/octave_analysis.yaml)"},{"location":"workflow_example/#3-octave-script-scriptseigen_analysism","text":"% scripts/eigen_analysis.m input_file = argv(){1}; output_file = argv(){2}; M = csvread(input_file); [V, D] = eig(M); eigenvalues = diag(D); csvwrite(output_file, eigenvalues); disp(\"Octave analysis complete. Eigenvalues saved.\");","title":"3. Octave Script (scripts/eigen_analysis.m)"},{"location":"workflow_example/#4-snakemake-pipeline-snakefile","text":"configfile: \"config.yaml\" rule all: input: \"results/eigenvalues_plot.png\" rule compute_eigenvalues: input: \"data/matrix.csv\" output: \"results/eigenvalues.csv\" params: octave_script = \"scripts/eigen_analysis.m\" conda: \"envs/octave_analysis.yaml\" shell: \"octave --no-gui --silent {params.octave_script} {input} {output}\" rule plot_eigenvalues: input: \"results/eigenvalues.csv\" output: \"results/eigenvalues_plot.png\" params: plot_script = \"scripts/plot_eigenvalues.py\" conda: \"envs/octave_analysis.yaml\" script: ''' import pandas as pd import matplotlib.pyplot as plt import numpy as np eigenvalues = pd.read_csv( snakemake.input[0], header=None ).values eigenvalues = np.sort(eigenvalues) plt.figure(figsize=(8, 6)) plt.bar( range(1, len(eigenvalues) + 1), eigenvalues ) plt.xlabel('Eigenvalue Index') plt.ylabel('Eigenvalue Magnitude') plt.title('Eigenvalues of the 3x3 Matrix') plt.xticks(range(1, 4)) plt.grid(axis='y') plt.savefig(snakemake.output[0]) print(snakemake.output[0]) '''","title":"4. Snakemake Pipeline (Snakefile)"},{"location":"workflow_example/#summary-of-execution-pid-to-plot","text":"This summary details the entire automated process, from the user providing the Persistent Identifier (PID) to the final plot generation, ensuring the role of the DoIP/FDO system is clearly represented. PID Resolution & Retrieval: The user initiates the run via the FDO Client using the workflow's PID. The FDO Client queries the DoIP server to resolve the PID, retrieving the RO-Crate's storage URL and its original Checksum . The Client downloads the RO-Crate archive (containing the Snakefile , envs/ , scripts/ , etc.) and extracts the contents to a temporary local directory. Integrity Verification: The Client calculates a new checksum of the downloaded RO-Crate and compares it to the value retrieved from the DoIP server. Execution proceeds only if the checksums match , guaranteeing the integrity and reproducibility of the workflow artifact. Snakemake Orchestration: The Client calls the local snakemake --use-conda command within the temporary directory. Rule 1: compute_eigenvalues (Octave): Conda creates the isolated environment containing the specified version of Octave . The rule executes the Octave script ( scripts/eigen_analysis.m ). Octave reads the input matrix and saves the computed eigenvalues to the intermediate file, results/eigenvalues.csv . Rule 2: plot_eigenvalues (Python/Matplotlib): Snakemake uses the same Conda environment (which contains Python, Pandas, and Matplotlib). The Python script reads the results/eigenvalues.csv file. It generates the bar plot visualization and saves the final result as results/eigenvalues_plot.png . Cleanup and Output: The workflow finishes, and the FDO Client presents the final output file(s) to the user. The Client performs cleanup, removing the temporary directory and the created Conda environments.","title":"Summary of Execution (PID to Plot)"},{"location":"workflows/","text":"Reproducible Workflows with Snakemake & FDO (Conda-Based) This document outlines the two main processes\u2014 Creation and Execution \u2014for using Snakemake workflows as Fair Digital Objects (FDOs) managed by a DoIP server. This strategy relies on the Conda environment management system to ensure reproducibility across Windows , Linux , and macOS environments without needing Docker or operating system compatibility layers. 1. Target System Preparation (User Role) The User must prepare their local operating system (Windows, Linux, or macOS) by installing the core components necessary to run the Conda-based Snakemake workflow. This setup is required once per machine. Step 1: Prepare the Windows Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. Step 2: Prepare the Linux Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. Step 3: Prepare the macOS Environment The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow. 2. Workflow Creation and FDO Registration (Creator Role) The Creator develops a workflow designed for maximum portability and registers the complete package as a persistent FDO artifact. 2.1. Develop the Snakemake Pipeline The workflow must explicitly use the Snakemake Conda integration to ensure cross-platform reproducibility. Write the Snakefile: Define the logic, rules, inputs, and outputs of your pipeline. Define Isolated Environments: For every external tool or dependency, create a dedicated environment.yaml file. These files are crucial as they precisely list the version-locked dependencies (e.g., fastqc=0.11.9 , python=3.9 ). Link Environments in the Snakefile: Ensure every rule points directly to its environment file using the conda: directive. Example Snakefile Snippet: python rule fastqc_report: input: \"data/{sample}.fastq\" output: \"results/{sample}_fastqc.html\" conda: \"envs/fastqc.yaml\" # Links to the environment definition shell: \"fastqc {input} -o {output}\" Test for Portability: Test the workflow on various operating systems (Windows, Linux, macOS) using the --use-conda flag to confirm that the environment files successfully build and the workflow executes identically across platforms. 2.2. Package and Register the FDO The validated workflow files are packaged as a Research Object Crate (RO-Crate) and registered to the DoIP/FDO system. Bundle Artifacts (RO-Crate): Package the Snakefile , all environment.yaml files, configuration files, and a README into a single RO-Crate archive (e.g., a ZIP or TAR archive). Calculate Checksum: Generate a cryptographic hash (e.g., SHA-256) of the final RO-Crate archive. Store and Mint PID: Upload the RO-Crate to the durable storage system. The automated registration service calls the DoIP server to mint a new PID . The PID's resolution data must store the storage URL and the Checksum . Register FDO: Submit the complete FDO metadata (PID, creator, description, input parameters, checksum , and dependency list) to the FDO Registry . 3. Workflow Execution (User Role) The User executes the verified, reproducible workflow on their local machine using the PID and local Conda installation. 3.1. Execute the FDO Client The FDO client automates the download, verification, and Snakemake execution steps. Initiate Run: The User executes the workflow using its PID and specifies the local input data directory. Example Command (Windows): bash fdo-run-client 20.500.12345/workflow_A01 --input \"C:\\User\\Data\\RawSequences\" --cores 4 Client Verification Logic: The client handles the critical, verifiable steps programmatically: * Resolve PID: Queries the DoIP server to retrieve the Storage URL and the original Checksum. * Download & Extract: Downloads the RO-Crate and extracts it to a temporary working directory. * Verify Integrity: Calculates the checksum of the downloaded file. Execution stops if this value does not match the PID's original checksum. * Prepare: Maps the user's input directory into the Snakemake configuration. Snakemake Execution: The client initiates the Snakemake run command: bash snakemake -s /path/to/Snakefile --cores 4 --use-conda --config input_path=\"/path/to/input/data\" 3.2. Guaranteed Reproducibility Across OS Because the --use-conda flag is employed: Snakemake reads the environment.yaml files within the downloaded RO-Crate. Conda automatically creates temporary, isolated software environments with the exact, version-locked dependencies compiled for the User's specific OS (Windows, Linux, or macOS). The workflow runs identically across all supported platforms, achieving high-fidelity reproducibility without external virtualization layers. Example See this example","title":"Workflows"},{"location":"workflows/#reproducible-workflows-with-snakemake-fdo-conda-based","text":"This document outlines the two main processes\u2014 Creation and Execution \u2014for using Snakemake workflows as Fair Digital Objects (FDOs) managed by a DoIP server. This strategy relies on the Conda environment management system to ensure reproducibility across Windows , Linux , and macOS environments without needing Docker or operating system compatibility layers.","title":"Reproducible Workflows with Snakemake &amp; FDO (Conda-Based)"},{"location":"workflows/#1-target-system-preparation-user-role","text":"The User must prepare their local operating system (Windows, Linux, or macOS) by installing the core components necessary to run the Conda-based Snakemake workflow. This setup is required once per machine.","title":"1. Target System Preparation (User Role)"},{"location":"workflows/#step-1-prepare-the-windows-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 1: Prepare the Windows Environment"},{"location":"workflows/#step-2-prepare-the-linux-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 2: Prepare the Linux Environment"},{"location":"workflows/#step-3-prepare-the-macos-environment","text":"The User needs four essential pieces of software installed: Conda/Mamba: Install Anaconda or Miniconda (preferred for a smaller footprint). Python: Ensure Python is installed (usually comes with Conda). Snakemake: Install the Snakemake engine: bash conda install -c conda-forge snakemake FDO Client: Install your custom command-line client for resolving PIDs and running the workflow.","title":"Step 3: Prepare the macOS Environment"},{"location":"workflows/#2-workflow-creation-and-fdo-registration-creator-role","text":"The Creator develops a workflow designed for maximum portability and registers the complete package as a persistent FDO artifact.","title":"2. Workflow Creation and FDO Registration (Creator Role)"},{"location":"workflows/#21-develop-the-snakemake-pipeline","text":"The workflow must explicitly use the Snakemake Conda integration to ensure cross-platform reproducibility. Write the Snakefile: Define the logic, rules, inputs, and outputs of your pipeline. Define Isolated Environments: For every external tool or dependency, create a dedicated environment.yaml file. These files are crucial as they precisely list the version-locked dependencies (e.g., fastqc=0.11.9 , python=3.9 ). Link Environments in the Snakefile: Ensure every rule points directly to its environment file using the conda: directive. Example Snakefile Snippet: python rule fastqc_report: input: \"data/{sample}.fastq\" output: \"results/{sample}_fastqc.html\" conda: \"envs/fastqc.yaml\" # Links to the environment definition shell: \"fastqc {input} -o {output}\" Test for Portability: Test the workflow on various operating systems (Windows, Linux, macOS) using the --use-conda flag to confirm that the environment files successfully build and the workflow executes identically across platforms.","title":"2.1. Develop the Snakemake Pipeline"},{"location":"workflows/#22-package-and-register-the-fdo","text":"The validated workflow files are packaged as a Research Object Crate (RO-Crate) and registered to the DoIP/FDO system. Bundle Artifacts (RO-Crate): Package the Snakefile , all environment.yaml files, configuration files, and a README into a single RO-Crate archive (e.g., a ZIP or TAR archive). Calculate Checksum: Generate a cryptographic hash (e.g., SHA-256) of the final RO-Crate archive. Store and Mint PID: Upload the RO-Crate to the durable storage system. The automated registration service calls the DoIP server to mint a new PID . The PID's resolution data must store the storage URL and the Checksum . Register FDO: Submit the complete FDO metadata (PID, creator, description, input parameters, checksum , and dependency list) to the FDO Registry .","title":"2.2. Package and Register the FDO"},{"location":"workflows/#3-workflow-execution-user-role","text":"The User executes the verified, reproducible workflow on their local machine using the PID and local Conda installation.","title":"3. Workflow Execution (User Role)"},{"location":"workflows/#31-execute-the-fdo-client","text":"The FDO client automates the download, verification, and Snakemake execution steps. Initiate Run: The User executes the workflow using its PID and specifies the local input data directory. Example Command (Windows): bash fdo-run-client 20.500.12345/workflow_A01 --input \"C:\\User\\Data\\RawSequences\" --cores 4 Client Verification Logic: The client handles the critical, verifiable steps programmatically: * Resolve PID: Queries the DoIP server to retrieve the Storage URL and the original Checksum. * Download & Extract: Downloads the RO-Crate and extracts it to a temporary working directory. * Verify Integrity: Calculates the checksum of the downloaded file. Execution stops if this value does not match the PID's original checksum. * Prepare: Maps the user's input directory into the Snakemake configuration. Snakemake Execution: The client initiates the Snakemake run command: bash snakemake -s /path/to/Snakefile --cores 4 --use-conda --config input_path=\"/path/to/input/data\"","title":"3.1. Execute the FDO Client"},{"location":"workflows/#32-guaranteed-reproducibility-across-os","text":"Because the --use-conda flag is employed: Snakemake reads the environment.yaml files within the downloaded RO-Crate. Conda automatically creates temporary, isolated software environments with the exact, version-locked dependencies compiled for the User's specific OS (Windows, Linux, or macOS). The workflow runs identically across all supported platforms, achieving high-fidelity reproducibility without external virtualization layers.","title":"3.2. Guaranteed Reproducibility Across OS"},{"location":"workflows/#example","text":"See this example","title":"Example"}]}